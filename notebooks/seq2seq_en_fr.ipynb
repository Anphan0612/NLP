{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq LSTM English→French (Multi30K)\n",
    "\n",
    "- Encoder-Decoder LSTM with fixed context vector, teacher forcing, greedy decoding.\n",
    "- Optional Luong attention + beam search for extended experiments.\n",
    "- Dataset: Multi30K en-fr raw (train/val/test) downloaded from GitHub.\n",
    "- Outputs: `best_model.pth`, `translate(sentence)`, BLEU score, loss plots, 5 example translations + error analysis notes.\n",
    "\n",
    "> Run this notebook on local GPU or Colab GPU (Python 3, torch ≥1.13).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (chỉ cài nếu thiếu). Chạy cell này đầu tiên!\n",
    "import subprocess\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "def check_and_install(package_name, install_cmd, import_name=None):\n",
    "    \"\"\"Kiểm tra package đã cài chưa, nếu chưa thì cài\"\"\"\n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    \n",
    "    try:\n",
    "        importlib.import_module(import_name)\n",
    "        print(f\"✓ {package_name} đã được cài đặt\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"⚠ {package_name} chưa có, đang cài đặt...\")\n",
    "        try:\n",
    "            subprocess.check_call(install_cmd, shell=True)\n",
    "            print(f\"✓ Đã cài đặt {package_name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Lỗi khi cài {package_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "# Kiểm tra và cài PyTorch (CUDA 12.1 compatible)\n",
    "try:\n",
    "    import torch\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"⚠ PyTorch có nhưng CUDA không khả dụng. Đang cài lại với CUDA support...\")\n",
    "        subprocess.check_call(\"pip install -U --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchtext==0.18.0 --extra-index-url https://download.pytorch.org/whl/cu121\", shell=True)\n",
    "    else:\n",
    "        print(f\"✓ PyTorch {torch.__version__} với CUDA đã sẵn sàng\")\n",
    "except ImportError:\n",
    "    print(\"⚠ PyTorch chưa có, đang cài đặt với CUDA 12.1...\")\n",
    "    subprocess.check_call(\"pip install -U --no-cache-dir torch==2.4.0 torchvision==0.19.0 torchtext==0.18.0 --extra-index-url https://download.pytorch.org/whl/cu121\", shell=True)\n",
    "\n",
    "# Kiểm tra và cài các dependencies khác\n",
    "check_and_install(\"spacy\", \"pip install -U spacy\", \"spacy\")\n",
    "check_and_install(\"nltk\", \"pip install -U nltk\", \"nltk\")\n",
    "check_and_install(\"tqdm\", \"pip install -U tqdm\", \"tqdm\")\n",
    "check_and_install(\"matplotlib\", \"pip install -U matplotlib\", \"matplotlib\")\n",
    "check_and_install(\"requests\", \"pip install -U requests\", \"requests\")\n",
    "\n",
    "# Download spaCy models (chỉ download nếu chưa có)\n",
    "import spacy\n",
    "try:\n",
    "    nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"✓ spaCy model en_core_web_sm đã có\")\n",
    "except OSError:\n",
    "    print(\"⚠ Đang tải spaCy model en_core_web_sm...\")\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "try:\n",
    "    nlp_fr = spacy.load(\"fr_core_news_sm\")\n",
    "    print(\"✓ spaCy model fr_core_news_sm đã có\")\n",
    "except OSError:\n",
    "    print(\"⚠ Đang tải spaCy model fr_core_news_sm...\")\n",
    "    spacy.cli.download(\"fr_core_news_sm\")\n",
    "\n",
    "# Download NLTK data\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    print(\"✓ NLTK punkt đã có\")\n",
    "except LookupError:\n",
    "    print(\"⚠ Đang tải NLTK punkt...\")\n",
    "    nltk.download('punkt', quiet=True)\n",
    "\n",
    "print(\"\\n✅ Tất cả dependencies đã sẵn sàng!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.5 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\AnPhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\AnPhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\AnPhan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3123, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3178, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3641, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3701, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\AnPhan\\AppData\\Local\\Temp\\ipykernel_3584\\2752276274.py\", line 9, in <module>\n",
      "    import torch\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\torch\\__init__.py\", line 2120, in <module>\n",
      "    from torch._higher_order_ops import cond\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\__init__.py\", line 1, in <module>\n",
      "    from .cond import cond\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\torch\\_higher_order_ops\\cond.py\", line 5, in <module>\n",
      "    import torch._subclasses.functional_tensor\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 42, in <module>\n",
      "    class FunctionalTensor(torch.Tensor):\n",
      "  File \"d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py\", line 258, in FunctionalTensor\n",
      "    cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "d:\\Workspaces-main\\NLP\\.venv\\Lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GPU INFORMATION\n",
      "============================================================\n",
      "Device: cuda\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "CUDA Version: 12.1\n",
      "PyTorch Version: 2.4.0+cu121\n",
      "GPU Memory: 4.00 GB\n",
      "GPU Memory Available: 0.00 GB reserved\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Device setup - tự động detect GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"=\" * 60)\n",
    "print(\"GPU INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"PyTorch Version: {torch.__version__}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU Memory Available: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB reserved\")\n",
    "else:\n",
    "    print(\"⚠ CUDA không khả dụng, sẽ chạy trên CPU (chậm hơn nhiều)\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ train.en already exists\n",
      "✓ train.fr already exists\n",
      "✓ val.en already exists\n",
      "✓ val.fr already exists\n",
      "✓ test.en already exists\n",
      "✓ test.fr already exists\n",
      "Data ready at D:\\Workspaces-main\\NLP\\notebooks\\data\\multi30k_en_fr\\raw\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path(\"data/multi30k_en_fr\")\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "CHECKPOINT_DIR = Path(\"checkpoints\")\n",
    "for p in [RAW_DIR, PROCESSED_DIR, CHECKPOINT_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download Multi30K en-fr raw files if missing\n",
    "# Using direct GitHub raw URLs (if 404, files may need to be cloned from repo)\n",
    "base_url = \"https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/\"\n",
    "urls = {\n",
    "    \"train.en\": base_url + \"train.en\",\n",
    "    \"train.fr\": base_url + \"train.fr\",\n",
    "    \"val.en\": base_url + \"val.en\",\n",
    "    \"val.fr\": base_url + \"val.fr\",\n",
    "    \"test.en\": base_url + \"test_2016_flickr.en\",\n",
    "    \"test.fr\": base_url + \"test_2016_flickr.fr\",\n",
    "}\n",
    "\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "def download_file(url, dest):\n",
    "    if dest.exists():\n",
    "        print(f\"✓ {dest.name} already exists\")\n",
    "        return True\n",
    "    print(f\"Downloading {dest.name} ...\")\n",
    "    try:\n",
    "        r = requests.get(url, timeout=60)\n",
    "        r.raise_for_status()\n",
    "        dest.write_bytes(r.content)\n",
    "        print(f\"✓ Downloaded {dest.name}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to download {dest.name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Try downloading from GitHub raw\n",
    "all_success = True\n",
    "for fname, url in urls.items():\n",
    "    if not download_file(url, RAW_DIR / fname):\n",
    "        all_success = False\n",
    "\n",
    "# Fallback: clone repo if direct download fails\n",
    "if not all_success:\n",
    "    print(\"\\nDirect download failed. Cloning repository (this may take a few minutes)...\")\n",
    "    clone_dir = DATA_DIR.parent / \"multi30k-dataset\"\n",
    "    \n",
    "    # Remove incomplete clone if exists\n",
    "    if clone_dir.exists():\n",
    "        if not (clone_dir / \"data\" / \"task1\" / \"raw\" / \"train.en\").exists():\n",
    "            print(\"Removing incomplete clone...\")\n",
    "            import shutil\n",
    "            shutil.rmtree(clone_dir, ignore_errors=True)\n",
    "    \n",
    "    # Clone if not exists or was removed\n",
    "    if not clone_dir.exists() or not (clone_dir / \"data\" / \"task1\" / \"raw\" / \"train.en\").exists():\n",
    "        print(\"Cloning multi30k/dataset repository...\")\n",
    "        result = subprocess.run(\n",
    "            [\"git\", \"clone\", \"--recursive\", \"https://github.com/multi30k/dataset.git\", str(clone_dir)],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=300\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Git clone error: {result.stderr}\")\n",
    "            print(\"Trying to check if files exist in different location...\")\n",
    "        else:\n",
    "            print(\"✓ Repository cloned successfully\")\n",
    "    \n",
    "    # Check and initialize submodules if needed\n",
    "    if (clone_dir / \".gitmodules\").exists():\n",
    "        print(\"Initializing git submodules...\")\n",
    "        subprocess.run([\"git\", \"submodule\", \"update\", \"--init\", \"--recursive\"], \n",
    "                      cwd=str(clone_dir), timeout=300, capture_output=True)\n",
    "    \n",
    "    # Search for files recursively\n",
    "    import shutil\n",
    "    import os\n",
    "    \n",
    "    def find_files_recursive(directory, pattern):\n",
    "        \"\"\"Find all files matching pattern recursively\"\"\"\n",
    "        found = []\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file == pattern:\n",
    "                    found.append(Path(root) / file)\n",
    "        return found\n",
    "    \n",
    "    print(\"Searching for data files...\")\n",
    "    \n",
    "    # Map of what we need vs what might be available\n",
    "    file_mapping = {\n",
    "        \"train.en\": [\"train.en\", \"train.lc.norm.tok.en\"],\n",
    "        \"train.fr\": [\"train.fr\", \"train.lc.norm.tok.fr\"],\n",
    "        \"val.en\": [\"val.en\", \"val.lc.norm.tok.en\"],\n",
    "        \"val.fr\": [\"val.fr\", \"val.lc.norm.tok.fr\"],\n",
    "        \"test.en\": [\"test_2016_flickr.en\", \"test_2016_flickr.lc.norm.tok.en\"],\n",
    "        \"test.fr\": [\"test_2016_flickr.fr\", \"test_2016_flickr.lc.norm.tok.fr\"],\n",
    "    }\n",
    "    \n",
    "    all_found = True\n",
    "    for target_name, possible_names in file_mapping.items():\n",
    "        found = False\n",
    "        for possible_name in possible_names:\n",
    "            found_files = find_files_recursive(clone_dir, possible_name)\n",
    "            if found_files:\n",
    "                src = found_files[0]\n",
    "                dest = RAW_DIR / target_name\n",
    "                if not dest.exists():\n",
    "                    # If it's a tokenized file, we'll use it as-is (spaCy will retokenize anyway)\n",
    "                    shutil.copy2(src, dest)\n",
    "                    print(f\"✓ Copied {target_name} from {src.name} (location: {src.parent})\")\n",
    "                else:\n",
    "                    print(f\"✓ {target_name} already exists\")\n",
    "                found = True\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            print(f\"✗ {target_name} not found (searched: {possible_names})\")\n",
    "            all_found = False\n",
    "    \n",
    "    if not all_found:\n",
    "        print(f\"\\nNote: Some raw files not found. Tokenized files may be used instead.\")\n",
    "        print(f\"Listing available files in data/task1/...\")\n",
    "        task1_dir = clone_dir / \"data\" / \"task1\"\n",
    "        if task1_dir.exists():\n",
    "            for subdir in [\"raw\", \"tok\"]:\n",
    "                subdir_path = task1_dir / subdir\n",
    "                if subdir_path.exists():\n",
    "                    print(f\"\\n{subdir}/:\")\n",
    "                    for item in sorted(subdir_path.glob(\"*\")):\n",
    "                        if item.is_file():\n",
    "                            print(f\"  {item.name}\")\n",
    "\n",
    "print(\"Data ready at\", RAW_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy tokenizers\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "spacy_fr = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "def tokenize_en(text: str) -> List[str]:\n",
    "    return [tok.text.lower() for tok in spacy_en.tokenizer(text.strip())]\n",
    "\n",
    "\n",
    "def tokenize_fr(text: str) -> List[str]:\n",
    "    return [tok.text.lower() for tok in spacy_fr.tokenizer(text.strip())]\n",
    "\n",
    "SPECIALS = [\"<unk>\", \"<pad>\", \"<sos>\", \"<eos>\"]\n",
    "UNK_IDX, PAD_IDX, SOS_IDX, EOS_IDX = 0, 1, 2, 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab sizes: 5894 6475\n"
     ]
    }
   ],
   "source": [
    "def read_parallel(split: str) -> Tuple[List[str], List[str]]:\n",
    "    en_path = RAW_DIR / f\"{split}.en\"\n",
    "    fr_path = RAW_DIR / f\"{split}.fr\"\n",
    "    with en_path.open(\"r\", encoding=\"utf-8\") as f_en, fr_path.open(\"r\", encoding=\"utf-8\") as f_fr:\n",
    "        en_lines = [line.strip() for line in f_en]\n",
    "        fr_lines = [line.strip() for line in f_fr]\n",
    "    assert len(en_lines) == len(fr_lines), \"Mismatched parallel data\"\n",
    "    return en_lines, fr_lines\n",
    "\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokens, specials, max_size=10000, min_freq=2):\n",
    "        self.specials = specials\n",
    "        self.stoi = {spec: idx for idx, spec in enumerate(specials)}\n",
    "        self.itos = specials.copy()\n",
    "        counter = Counter()\n",
    "        for token_list in tokens:\n",
    "            counter.update(token_list)\n",
    "        for token, count in counter.most_common(max_size - len(specials)):\n",
    "            if count >= min_freq and token not in self.stoi:\n",
    "                self.stoi[token] = len(self.itos)\n",
    "                self.itos.append(token)\n",
    "    \n",
    "    def __getitem__(self, token):\n",
    "        return self.stoi.get(token, UNK_IDX)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    def get_itos(self):\n",
    "        return self.itos\n",
    "\n",
    "\n",
    "def build_vocabs(max_size=10000, min_freq=2):\n",
    "    train_en, train_fr = read_parallel(\"train\")\n",
    "    en_tokens = [tokenize_en(line) for line in train_en]\n",
    "    fr_tokens = [tokenize_fr(line) for line in train_fr]\n",
    "    en_vocab = Vocab(en_tokens, SPECIALS, max_size=max_size, min_freq=min_freq)\n",
    "    fr_vocab = Vocab(fr_tokens, SPECIALS, max_size=max_size, min_freq=min_freq)\n",
    "    return en_vocab, fr_vocab\n",
    "\n",
    "\n",
    "en_vocab, fr_vocab = build_vocabs()\n",
    "print(\"Vocab sizes:\", len(en_vocab), len(fr_vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader config: num_workers=0, pin_memory=False\n",
      "Batches: 454 16 16\n"
     ]
    }
   ],
   "source": [
    "class ParallelTextDataset(Dataset):\n",
    "    def __init__(self, split: str):\n",
    "        self.en_lines, self.fr_lines = read_parallel(split)\n",
    "        self.split = split\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.en_lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        en_tok = tokenize_en(self.en_lines[idx])\n",
    "        fr_tok = tokenize_fr(self.fr_lines[idx])\n",
    "        en_ids = [SOS_IDX] + [en_vocab[t] for t in en_tok] + [EOS_IDX]\n",
    "        fr_ids = [SOS_IDX] + [fr_vocab[t] for t in fr_tok] + [EOS_IDX]\n",
    "        return torch.tensor(en_ids, dtype=torch.long), torch.tensor(fr_ids, dtype=torch.long)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    # sort by src length desc for packing\n",
    "    src_batch = list(src_batch)\n",
    "    tgt_batch = list(tgt_batch)\n",
    "    lengths = torch.tensor([len(x) for x in src_batch])\n",
    "    sorted_idx = torch.argsort(lengths, descending=True)\n",
    "    src_batch = [src_batch[i] for i in sorted_idx]\n",
    "    tgt_batch = [tgt_batch[i] for i in sorted_idx]\n",
    "    src_padded = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_padded = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_padded.to(device), tgt_padded.to(device), lengths[sorted_idx].to(device)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_ds = ParallelTextDataset(\"train\")\n",
    "val_ds = ParallelTextDataset(\"val\")\n",
    "test_ds = ParallelTextDataset(\"test\")\n",
    "\n",
    "# Tối ưu DataLoader cho GPU local\n",
    "# num_workers: số process để load data (0 = main process, 2-4 cho Windows)\n",
    "# pin_memory: KHÔNG dùng khi collate_fn đã chuyển tensor sang GPU (tránh lỗi pin_memory trên CUDA tensors)\n",
    "import os\n",
    "NUM_WORKERS = 0 if os.name == 'nt' else 4  # Windows thường dùng 0, Linux/Mac dùng 4\n",
    "PIN_MEMORY = torch.cuda.is_available() and False  # buộc tắt pin_memory\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=PIN_MEMORY\n",
    ")\n",
    "\n",
    "print(f\"DataLoader config: num_workers={NUM_WORKERS}, pin_memory={PIN_MEMORY}\")\n",
    "print(\"Batches:\", len(train_loader), len(val_loader), len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers=2, dropout=0.3, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=PAD_IDX)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout, bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "    def forward(self, src, src_lengths):\n",
    "        # src: [src_len, batch]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        packed = pack_padded_sequence(embedded, src_lengths.cpu(), enforce_sorted=True)\n",
    "        outputs, (hidden, cell) = self.rnn(packed)\n",
    "        outputs, _ = pad_packed_sequence(outputs)  # [src_len, batch, hid_dim * num_directions]\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "\n",
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hid_dim, hid_dim, bias=False)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs, mask=None):\n",
    "        # hidden: [batch, hid_dim]; encoder_outputs: [src_len, batch, hid_dim]\n",
    "        scores = torch.einsum(\"bh,sbh->bs\", self.attn(hidden), encoder_outputs)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_weights = torch.softmax(scores, dim=1)  # [batch, src_len]\n",
    "        context = torch.einsum(\"bs,sbh->bh\", attn_weights, encoder_outputs)\n",
    "        return context, attn_weights\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers=2, dropout=0.3, use_attention=False):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=PAD_IDX)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim * (2 if use_attention else 1), output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.use_attention = use_attention\n",
    "        self.attention = LuongAttention(hid_dim) if use_attention else None\n",
    "\n",
    "    def forward(self, input, hidden, cell, encoder_outputs=None, mask=None):\n",
    "        # input: [batch]; hidden/cell: [n_layers, batch, hid_dim]\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))  # [1, batch, emb_dim]\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        # output: [1, batch, hid_dim]\n",
    "        output = output.squeeze(0)\n",
    "        if self.use_attention:\n",
    "            context, attn_weights = self.attention(output, encoder_outputs, mask)\n",
    "            output_cat = torch.cat((output, context), dim=1)\n",
    "            prediction = self.fc_out(output_cat)\n",
    "        else:\n",
    "            prediction = self.fc_out(output)\n",
    "            attn_weights = None\n",
    "        return prediction, hidden, cell, attn_weights\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx=PAD_IDX, use_attention=False):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "        self.use_attention = use_attention\n",
    "\n",
    "    def make_mask(self, src):\n",
    "        # src: [src_len, batch]\n",
    "        return (src != self.pad_idx).permute(1, 0)  # [batch, src_len]\n",
    "\n",
    "    def forward(self, src, src_lengths, trg, teacher_forcing_ratio=0.5):\n",
    "        # src: [src_len, batch]; trg: [trg_len, batch]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.embedding.num_embeddings\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size, device=device)\n",
    "        encoder_outputs, hidden, cell = self.encoder(src, src_lengths)\n",
    "        input = trg[0, :]  # first token = <sos>\n",
    "        mask = self.make_mask(src) if self.use_attention else None\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell, _ = self.decoder(input, hidden, cell, encoder_outputs, mask)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and model init\n",
    "# BẢN GỐC (khớp 100% với đề bài):\n",
    "EMB_DIM = 300\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.3  # Đề bài: 0.3-0.5, chọn 0.3\n",
    "USE_ATTENTION = True  # set False to train baseline without attention\n",
    "BEAM_SIZE = 5\n",
    "MAX_LEN = 50\n",
    "TEACHER_FORCING = 0.5  # Đề bài: 0.5 cố định\n",
    "LR = 0.001  # Đề bài: Adam(lr=0.001)\n",
    "EPOCHS = 15  # Đề bài: 10-20\n",
    "PATIENCE = 3  # Đề bài: dừng nếu val_loss không giảm sau 3 epoch\n",
    "\n",
    "# BẢN CẢI TIẾN (để so sánh - comment lại):\n",
    "# DROPOUT = 0.45  # Tăng để giảm overfitting\n",
    "# TEACHER_FORCING_START = 0.7  # Scheduled teacher forcing\n",
    "# TEACHER_FORCING_END = 0.3\n",
    "# LABEL_SMOOTHING = 0.1  # Label smoothing\n",
    "# LR = 8e-4  # Learning rate thấp hơn\n",
    "# PATIENCE = 4  # Patience cao hơn\n",
    "\n",
    "enc = Encoder(len(en_vocab), EMB_DIM, HID_DIM, n_layers=N_LAYERS, dropout=DROPOUT)\n",
    "dec = Decoder(len(fr_vocab), EMB_DIM, HID_DIM, n_layers=N_LAYERS, dropout=DROPOUT, use_attention=USE_ATTENTION)\n",
    "model = Seq2Seq(enc, dec, pad_idx=PAD_IDX, use_attention=USE_ATTENTION).to(device)\n",
    "\n",
    "# BẢN GỐC (khớp đề bài):\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)  # Đề bài: không có label_smoothing\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)  # Đề bài: Adam(lr=0.001), không có weight_decay\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=1)  # Đề bài: tùy chọn\n",
    "\n",
    "# BẢN CẢI TIẾN (để so sánh - comment lại):\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-5)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start, end):\n",
    "    elapsed = end - start\n",
    "    return int(elapsed // 60), int(elapsed % 60)\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, teacher_forcing=0.5):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg, src_lengths in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(src, src_lengths, trg, teacher_forcing_ratio=teacher_forcing)\n",
    "        # outputs: [trg_len, batch, vocab]\n",
    "        output_dim = outputs.shape[-1]\n",
    "        outputs_flat = outputs[1:].reshape(-1, output_dim)\n",
    "        trg_flat = trg[1:].reshape(-1)\n",
    "        loss = criterion(outputs_flat, trg_flat)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, src_lengths in tqdm(loader, desc=\"Val\", leave=False):\n",
    "            outputs = model(src, src_lengths, trg, teacher_forcing_ratio=0.0)\n",
    "            output_dim = outputs.shape[-1]\n",
    "            outputs_flat = outputs[1:].reshape(-1, output_dim)\n",
    "            trg_flat = trg[1:].reshape(-1)\n",
    "            loss = criterion(outputs_flat, trg_flat)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train 4.445 | Val 4.519 | TF 0.5 | Time 1m 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 | Train 3.417 | Val 3.980 | TF 0.5 | Time 1m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 | Train 2.834 | Val 3.684 | TF 0.5 | Time 1m 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 | Train 2.472 | Val 3.595 | TF 0.5 | Time 1m 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 | Train 2.228 | Val 3.371 | TF 0.5 | Time 1m 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 | Train 2.037 | Val 3.413 | TF 0.5 | Time 1m 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 | Train 1.884 | Val 3.288 | TF 0.5 | Time 5m 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 | Train 1.756 | Val 3.313 | TF 0.5 | Time 1m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 | Train 1.650 | Val 3.284 | TF 0.5 | Time 1m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 | Train 1.555 | Val 3.313 | TF 0.5 | Time 1m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 | Train 1.482 | Val 3.317 | TF 0.5 | Time 1m 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 | Train 1.329 | Val 3.232 | TF 0.5 | Time 1m 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 | Train 1.284 | Val 3.199 | TF 0.5 | Time 1m 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 | Train 1.236 | Val 3.186 | TF 0.5 | Time 1m 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 | Train 1.185 | Val 3.256 | TF 0.5 | Time 1m 5s\n",
      "Best checkpoint: checkpoints\\best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "patience_counter = 0\n",
    "train_losses, val_losses = [], []\n",
    "best_path = CHECKPOINT_DIR / \"best_model.pth\"\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "    # BẢN GỐC (khớp đề bài): Teacher forcing 0.5 cố định\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, teacher_forcing=TEACHER_FORCING)\n",
    "    \n",
    "    # BẢN CẢI TIẾN (để so sánh - comment lại):\n",
    "    # Scheduled teacher forcing: decay linearly from START to END\n",
    "    # current_tf = TEACHER_FORCING_START - (TEACHER_FORCING_START - TEACHER_FORCING_END) * (epoch - 1) / (EPOCHS - 1)\n",
    "    # current_tf = max(TEACHER_FORCING_END, current_tf)\n",
    "    # train_loss = train_one_epoch(model, train_loader, optimizer, criterion, teacher_forcing=current_tf)\n",
    "    \n",
    "    val_loss = evaluate(model, val_loader, criterion)\n",
    "    scheduler.step(val_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save({\"model_state\": model.state_dict(), \"config\": {\n",
    "            \"EMB_DIM\": EMB_DIM,\n",
    "            \"HID_DIM\": HID_DIM,\n",
    "            \"N_LAYERS\": N_LAYERS,\n",
    "            \"DROPOUT\": DROPOUT,\n",
    "            \"USE_ATTENTION\": USE_ATTENTION,\n",
    "            \"EN_VOCAB\": len(en_vocab),\n",
    "            \"FR_VOCAB\": len(fr_vocab),\n",
    "            \"PAD_IDX\": PAD_IDX,\n",
    "        }}, best_path)\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    mins, secs = epoch_time(start_time, time.time())\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | Train {train_loss:.3f} | Val {val_loss:.3f} | TF {TEACHER_FORCING} | Time {mins}m {secs}s\")\n",
    "\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "print(\"Best checkpoint:\", best_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Train/Val Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference helpers\n",
    "\n",
    "def ids_to_sentence(ids, vocab):\n",
    "    tokens = []\n",
    "    for i in ids:\n",
    "        if i == EOS_IDX:\n",
    "            break\n",
    "        if i not in (SOS_IDX, PAD_IDX):\n",
    "            tokens.append(vocab.get_itos()[i])\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "def encode_sentence(sentence, tokenizer, vocab):\n",
    "    toks = [t for t in tokenizer(sentence)]\n",
    "    ids = [SOS_IDX] + [vocab[t] for t in toks] + [EOS_IDX]\n",
    "    return torch.tensor(ids, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "def greedy_decode(model, sentence, max_len=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src_tensor = encode_sentence(sentence, tokenize_en, en_vocab).unsqueeze(1)\n",
    "        src_len = torch.tensor([src_tensor.shape[0]], device=device)\n",
    "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_len)\n",
    "        mask = model.make_mask(src_tensor) if model.use_attention else None\n",
    "        input_token = torch.tensor([SOS_IDX], device=device)\n",
    "        preds = []\n",
    "        for _ in range(max_len):\n",
    "            output, hidden, cell, _ = model.decoder(input_token, hidden, cell, encoder_outputs, mask)\n",
    "            top1 = output.argmax(1)\n",
    "            if top1.item() == EOS_IDX:\n",
    "                break\n",
    "            preds.append(top1.item())\n",
    "            input_token = top1\n",
    "        return ids_to_sentence(preds, fr_vocab)\n",
    "\n",
    "\n",
    "def beam_search_decode(model, sentence, beam_size=5, max_len=50):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src_tensor = encode_sentence(sentence, tokenize_en, en_vocab).unsqueeze(1)\n",
    "        src_len = torch.tensor([src_tensor.shape[0]], device=device)\n",
    "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_len)\n",
    "        mask = model.make_mask(src_tensor) if model.use_attention else None\n",
    "\n",
    "        beams = [(0.0, [SOS_IDX], hidden, cell)]\n",
    "        completed = []\n",
    "        for _ in range(max_len):\n",
    "            new_beams = []\n",
    "            for log_prob, seq, h, c in beams:\n",
    "                inp = torch.tensor([seq[-1]], device=device)\n",
    "                output, h_new, c_new, _ = model.decoder(inp, h, c, encoder_outputs, mask)\n",
    "                probs = torch.log_softmax(output, dim=1)\n",
    "                topk_logp, topk_idx = probs.topk(beam_size, dim=1)\n",
    "                for k in range(beam_size):\n",
    "                    next_token = topk_idx[0, k].item()\n",
    "                    new_log_prob = log_prob + topk_logp[0, k].item()\n",
    "                    new_seq = seq + [next_token]\n",
    "                    if next_token == EOS_IDX:\n",
    "                        completed.append((new_log_prob, new_seq))\n",
    "                    else:\n",
    "                        new_beams.append((new_log_prob, new_seq, h_new, c_new))\n",
    "            beams = sorted(new_beams, key=lambda x: x[0], reverse=True)[:beam_size]\n",
    "            if not beams:\n",
    "                break\n",
    "        if completed:\n",
    "            best = max(completed, key=lambda x: x[0])\n",
    "        else:\n",
    "            best = max(beams, key=lambda x: x[0])\n",
    "        return ids_to_sentence(best[1], fr_vocab)\n",
    "\n",
    "\n",
    "def translate(sentence, use_beam=False):\n",
    "    if use_beam:\n",
    "        return beam_search_decode(model, sentence, beam_size=BEAM_SIZE, max_len=MAX_LEN)\n",
    "    return greedy_decode(model, sentence, max_len=MAX_LEN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BLEU scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU (greedy): 45.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU (beam search, size=5): 47.51%\n",
      "Improvement: +1.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# BLEU evaluation on test set\n",
    "\n",
    "def compute_bleu(model, loader, n_samples=None, use_beam=False):\n",
    "    model.eval()\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for i, (src, trg, src_lengths) in enumerate(tqdm(loader, desc=\"Test\", leave=False)):\n",
    "            # decode each sentence individually for simplicity\n",
    "            for b in range(src.shape[1]):\n",
    "                src_sent = src[:, b].tolist()\n",
    "                trg_sent = trg[:, b].tolist()\n",
    "                # reconstruct raw English sentence for translation\n",
    "                en_tokens = [en_vocab.get_itos()[idx] for idx in src_sent if idx not in (PAD_IDX, SOS_IDX, EOS_IDX)]\n",
    "                src_text = \" \".join(en_tokens)\n",
    "                pred = translate(src_text, use_beam=use_beam)\n",
    "                ref_tokens = [fr_vocab.get_itos()[idx] for idx in trg_sent if idx not in (PAD_IDX, SOS_IDX, EOS_IDX, EOS_IDX)]\n",
    "                scores.append(sentence_bleu([ref_tokens], pred.split(), smoothing_function=smoothie))\n",
    "            if n_samples and len(scores) >= n_samples:\n",
    "                break\n",
    "    return sum(scores) / len(scores)\n",
    "\n",
    "# Compute BLEU (may take time). Uncomment to run after training.\n",
    "print(\"Computing BLEU scores...\")\n",
    "bleu_greedy = compute_bleu(model, test_loader, n_samples=200, use_beam=False)\n",
    "print(f\"BLEU (greedy): {bleu_greedy*100:.2f}%\")\n",
    "\n",
    "# Compare with beam search (optional, for extension)\n",
    "bleu_beam = compute_bleu(model, test_loader, n_samples=200, use_beam=True)\n",
    "print(f\"BLEU (beam search, size={BEAM_SIZE}): {bleu_beam*100:.2f}%\")\n",
    "print(f\"Improvement: +{(bleu_beam - bleu_greedy)*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "5 VÍ DỤ DỊCH + PHÂN TÍCH\n",
      "============================================================\n",
      "\n",
      "[1] EN: a man is riding a bicycle\n",
      "    FR (greedy): un homme fait du vélo\n",
      "    FR (beam):   un homme fait du vélo\n",
      "\n",
      "[2] EN: children are playing in the park\n",
      "    FR (greedy): des enfants jouent dans le parc\n",
      "    FR (beam):   des enfants jouent dans le parc\n",
      "\n",
      "[3] EN: a woman is sitting at a table\n",
      "    FR (greedy): une femme est assise à une table\n",
      "    FR (beam):   une femme est assise à une table\n",
      "\n",
      "[4] EN: two dogs are running on the beach\n",
      "    FR (greedy): deux chiens courent sur la plage\n",
      "    FR (beam):   deux chiens courent sur la plage\n",
      "\n",
      "[5] EN: the man holds a red umbrella\n",
      "    FR (greedy): l&apos ; homme tient un parapluie rouge\n",
      "    FR (beam):   l&apos ; homme tient un parapluie rouge\n",
      "\n",
      "============================================================\n",
      "PHÂN TÍCH LỖI PHỔ BIẾN:\n",
      "============================================================\n",
      "\n",
      "1. Từ hiếm (OOV) → <unk>:\n",
      "   - Từ không có trong vocab 10k → mất thông tin cụ thể\n",
      "   - Giải pháp: Tăng vocab size, dùng BPE/subword tokenization\n",
      "\n",
      "2. Câu dài → mất thông tin (do context vector cố định):\n",
      "   - Encoder chỉ truyền (h_n, c_n) → thông tin bị nén\n",
      "   - Giải pháp: Đã dùng attention (Luong) để tập trung vào phần liên quan\n",
      "\n",
      "3. Dịch sai ngữ pháp, thiếu từ:\n",
      "   - Model có thể bỏ qua một số từ hoặc sai thứ tự\n",
      "   - Giải pháp: Beam search (đã implement) giúp tìm chuỗi tốt hơn\n",
      "\n",
      "4. Overfitting:\n",
      "   - Train loss giảm nhưng val loss chững lại sau một số epoch\n",
      "   - Giải pháp hiện tại: Dropout 0.3, early stopping (patience=3)\n",
      "   - Đề xuất cải tiến: Tăng dropout lên 0.4-0.5, thêm label smoothing\n",
      "\n",
      "5. Exposure bias:\n",
      "   - Training dùng ground truth (teacher forcing 0.5), inference dùng prediction → mismatch\n",
      "   - Giải pháp hiện tại: Teacher forcing 0.5 cố định (theo đề bài)\n",
      "   - Đề xuất cải tiến: Scheduled teacher forcing (giảm dần từ 0.7 → 0.3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5 ví dụ dịch + phân tích lỗi (yêu cầu báo cáo)\n",
    "sentences = [\n",
    "    \"a man is riding a bicycle\",\n",
    "    \"children are playing in the park\",\n",
    "    \"a woman is sitting at a table\",\n",
    "    \"two dogs are running on the beach\",\n",
    "    \"the man holds a red umbrella\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"5 VÍ DỤ DỊCH + PHÂN TÍCH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "examples = []\n",
    "for i, s in enumerate(sentences, 1):\n",
    "    pred_greedy = translate(s, use_beam=False)\n",
    "    pred_beam = translate(s, use_beam=True)\n",
    "    \n",
    "    print(f\"\\n[{i}] EN: {s}\")\n",
    "    print(f\"    FR (greedy): {pred_greedy}\")\n",
    "    print(f\"    FR (beam):   {pred_beam}\")\n",
    "    \n",
    "    examples.append({\n",
    "        \"en\": s,\n",
    "        \"greedy\": pred_greedy,\n",
    "        \"beam\": pred_beam\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PHÂN TÍCH LỖI PHỔ BIẾN:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. Từ hiếm (OOV) → <unk>:\n",
    "   - Từ không có trong vocab 10k → mất thông tin cụ thể\n",
    "   - Giải pháp: Tăng vocab size, dùng BPE/subword tokenization\n",
    "\n",
    "2. Câu dài → mất thông tin (do context vector cố định):\n",
    "   - Encoder chỉ truyền (h_n, c_n) → thông tin bị nén\n",
    "   - Giải pháp: Đã dùng attention (Luong) để tập trung vào phần liên quan\n",
    "\n",
    "3. Dịch sai ngữ pháp, thiếu từ:\n",
    "   - Model có thể bỏ qua một số từ hoặc sai thứ tự\n",
    "   - Giải pháp: Beam search (đã implement) giúp tìm chuỗi tốt hơn\n",
    "\n",
    "4. Overfitting:\n",
    "   - Train loss giảm nhưng val loss chững lại sau một số epoch\n",
    "   - Giải pháp hiện tại: Dropout 0.3, early stopping (patience=3)\n",
    "   - Đề xuất cải tiến: Tăng dropout lên 0.4-0.5, thêm label smoothing\n",
    "\n",
    "5. Exposure bias:\n",
    "   - Training dùng ground truth (teacher forcing 0.5), inference dùng prediction → mismatch\n",
    "   - Giải pháp hiện tại: Teacher forcing 0.5 cố định (theo đề bài)\n",
    "   - Đề xuất cải tiến: Scheduled teacher forcing (giảm dần từ 0.7 → 0.3)\n",
    "\"\"\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
